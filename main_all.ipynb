{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import crepe\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import mir_eval\n",
    "from mir_eval.sonify import chords\n",
    "from mir_eval.display import segments\n",
    "from madmom.audio.chroma import DeepChromaProcessor\n",
    "from madmom.features.chords import DeepChromaChordRecognitionProcessor\n",
    "from madmom.features.key import CNNKeyRecognitionProcessor\n",
    "from madmom.features.key import key_prediction_to_label\n",
    "from madmom.features.beats import RNNBeatProcessor\n",
    "from madmom.features.beats import BeatTrackingProcessor\n",
    "from mingus.core import progressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chord_truth(filepath):\n",
    "    \"\"\" gets the truth chord data from filepath\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Path to text file with chord truth data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chord_intervals : np.ndarray, shape=(n, 2)\n",
    "        Chord intervals [start_time, end_time] in seconds\n",
    "    chord_labels : list, shape=(n,)\n",
    "        List of chord labels, e.g. ['A:maj', 'G:min', ...]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    chord_intervals = np.zeros([0,2])\n",
    "    chord_labels = np.array([])\n",
    "    f = open(filepath, 'r')\n",
    "    gt = f.readlines()\n",
    "\n",
    "    for rl in gt:\n",
    "        i = rl.split(' ')\n",
    "        chord_intervals = np.vstack([chord_intervals,[float(i[0]),float(i[1])]])\n",
    "        chord_labels = np.append(chord_labels,i[2].strip())\n",
    "    return chord_intervals, chord_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bass_notes(chord_labels, key):\n",
    "    \"\"\" Extract the bass note from the reference labels with defined key\n",
    "    chord_labels: Text defined chords \n",
    "    key: one of the twelve keys\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    scale = ['C','Db','D','Eb','E','F','Gb','G','Ab','A','Bb','B',\n",
    "             'C','Db','D','Eb','E','F','Gb','G','Ab','A','Bb','B','C']\n",
    "    \n",
    "    intervals_major = {\n",
    "                        '2':2,\n",
    "                        '3':4,\n",
    "                        '4':5,\n",
    "                        '5':7,\n",
    "                        '6':9,\n",
    "                        '7':10,\n",
    "                        '9':2\n",
    "                      }\n",
    "    \n",
    "    intervals_minor = {\n",
    "                    '2':2,\n",
    "                    '3':3,\n",
    "                    '4':5,\n",
    "                    '5':7,\n",
    "                    '6':8,\n",
    "                    '7':10,\n",
    "                    '9':2\n",
    "                      }\n",
    "\n",
    "    bass_notes = np.array([])\n",
    "        \n",
    "    for label in chord_labels:\n",
    "        if '/' not in label:\n",
    "            if '#' in label or 'b' in label:\n",
    "                bass_notes = np.append(bass_notes,label[0:2])\n",
    "            else:\n",
    "                bass_notes = np.append(bass_notes,label[0])\n",
    "\n",
    "        else:\n",
    "            root = label.split('/')[0][0]   \n",
    "            root_idx = scale.index(root)\n",
    "            \n",
    "            inversion_info = label.split('/')[-1][-1]\n",
    "            \n",
    "            if 'minor' in key:\n",
    "                if 'b' in inversion_info:\n",
    "                    label = str(scale[root_idx + (int(intervals_minor[inversion_info])) - 1])\n",
    "\n",
    "                elif '#' in inversion_info:\n",
    "                    label = str(scale[root_idx + (int(intervals_minor[inversion_info])) + 1])\n",
    "\n",
    "                else:\n",
    "                    label = str(scale[root_idx + (int(intervals_minor[inversion_info]))])\n",
    "            \n",
    "            else:\n",
    "                if 'b' in inversion_info:\n",
    "                    label = str(scale[root_idx + (int(intervals_major[inversion_info])) - 1])\n",
    "\n",
    "                elif '#' in inversion_info:\n",
    "                    label = str(scale[root_idx + (int(intervals_major[inversion_info])) + 1])\n",
    "\n",
    "                else:\n",
    "                    label = str(scale[root_idx + (int(intervals_major[inversion_info]))])\n",
    "            \n",
    "            bass_notes = np.append(bass_notes,label)\n",
    "    \n",
    "    return bass_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bass_notes_to_midi(bass_notes):\n",
    "    \"\"\" Converts bass notes to midi notes in the first octave. Excludes if the bass note is N \"\"\"\n",
    "    bass_midi  = np.zeros_like(bass_notes, dtype=np.float)\n",
    "    bass_midi[bass_notes != 'N'] = librosa.note_to_midi(bass_notes[bass_notes != 'N']).astype(np.float)\n",
    "    bass_midi = np.mod(bass_midi, 12)\n",
    "    bass_midi[bass_notes == 'N'] = np.nan ## -1?\n",
    "    return bass_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_truth(filepath):\n",
    "    \"\"\" gets the truth key data from filepath\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Path to text file with chord truth data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    key_labels : list, shape=(n,)\n",
    "        Chord intervals [start_time, end_time] in seconds\n",
    "        List of key labels, e.g. ['C', 'Silence' ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    key_labels = []\n",
    "    f = open(filepath, 'r')\n",
    "    gt = f.readlines()\n",
    "\n",
    "    for rl in gt:\n",
    "        i = rl.split('\\t')\n",
    "        key_labels.append(i[-1].strip())\n",
    "        \n",
    "    return key_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beats_truth(filepath):\n",
    "    \"\"\"Get beats from annotation dataset\"\"\"\n",
    "    reference_beats = []\n",
    "    f = open(filepath, 'r')\n",
    "    gt = f.readlines()\n",
    "    \n",
    "    reference_beats.append(np.loadtxt(filepath))\n",
    "    \n",
    "    reference_beats = reference_beats[0][:,0]\n",
    "    \n",
    "    return reference_beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bass_note(bass_f0, time_axis, chord_intervals, chord_labels):\n",
    "    \"\"\" Estimates the most likely bass note from a bass_f0 vector defined at time_axis\n",
    "    and aided by chord_intervals and chord_labels\n",
    "    \"\"\"\n",
    "    bass_midi = librosa.hz_to_midi(bass_f0)\n",
    "    bass_midi = np.round(bass_midi) # Ow well...\n",
    "    bass_midi = np.mod(bass_midi, 12)\n",
    "    \n",
    "    est_bass_note = np.array([])\n",
    "    \n",
    "    for i in np.arange(np.size(chord_labels)):\n",
    "        start_time = chord_intervals[i,0]\n",
    "        end_time = chord_intervals[i,1]\n",
    "        idx = np.logical_and(time_axis > start_time, time_axis <= end_time)\n",
    "        cur_midi_note, _ = stats.mode(bass_midi[idx]) # \n",
    "        # Maybe add something that tells us if the current bass_note is part of the current chord\n",
    "        # Mingus maybe?\n",
    "        cur_label = librosa.midi_to_note(float(cur_midi_note), octave=False, unicode=False)\n",
    "        est_bass_note = np.append(est_bass_note, cur_label)\n",
    "        \n",
    "    return est_bass_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_chord_and_bass_labels(chord_labels, bass_notes):\n",
    "    \"\"\" Combine Bass note and chord label according to what MIR_Eval\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B', 'C']\n",
    "    \n",
    "    intervals_major = {\n",
    "                        1:'b2',\n",
    "                        2:'2',\n",
    "                        3:'b3',\n",
    "                        4:'3',\n",
    "                        5:'4',\n",
    "                        6:'b5',\n",
    "                        7:'5',\n",
    "                        8:'b6',\n",
    "                        9:'6',\n",
    "                        10:'7',\n",
    "                        11:'b7'\n",
    "                      }\n",
    "    \n",
    "    intervals_minor = {\n",
    "                        1:'b2',\n",
    "                        2:'2',\n",
    "                        3:'3',\n",
    "                        4:'#3',\n",
    "                        5:'4',\n",
    "                        6:'b5',\n",
    "                        7:'5',\n",
    "                        8:'6',\n",
    "                        9:'#6',\n",
    "                        10:'7',\n",
    "                        11:'#7'\n",
    "                        }\n",
    "    \n",
    "    chordWithInversion = np.array([])\n",
    "    roots = np.array([])\n",
    "    for label in est_chord_labels_expanded:\n",
    "        if '#' in label or 'b' in label:\n",
    "            roots = np.append(roots, label[0:2])      \n",
    "        else:\n",
    "            roots = np.append(roots, label[0])\n",
    "            \n",
    "    for i in np.arange(np.size(chord_labels)):\n",
    "        if roots[i] == 'N':\n",
    "            chordWithInversion = np.append(chordWithInversion, chord_labels[i])\n",
    "            continue\n",
    "\n",
    "        rootIdx = scale.index(roots[i])\n",
    "        bassIdx = scale.index(bass_notes[i])\n",
    "        interval = np.mod(bassIdx - rootIdx, 12)\n",
    "        \n",
    "        if interval == 0:\n",
    "            chordWithInversion = np.append(chordWithInversion, chord_labels[i])\n",
    "            continue\n",
    "                \n",
    "        if 'min' in chord_labels[i]:\n",
    "            bassDegree = intervals_minor[interval]\n",
    "        else:\n",
    "            bassDegree = intervals_major[interval]\n",
    "        curChord = chord_labels[i] + \"/\" + bassDegree\n",
    "        chordWithInversion = np.append(chordWithInversion, curChord)\n",
    "    return chordWithInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score1 = np.array([])\n",
    "mean_score2 = np.array([])\n",
    "mean_score3 = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all folders and files to be used\n",
    "\n",
    "song_names = [\"07_-_Please_Please_Me\", \"03_-_All_My_Loving\", \"13_-_Yesterday\",\"07_-_Michelle\", \"05_-_Here,_There_And_Everywhere\",\"10_-_For_No_One\",\"04_-_Getting_Better\", \"02_-_The_Fool_On_The_Hill\", \"09_-_Penny_Lane\",\"CD2_-_03_-_Mother_Nature's_Son\"]\n",
    "album_names = [\"01_-_Please_Please_Me\", \"02_-_With_the_Beatles\", \"05_-_Help!\",\"06_-_Rubber_Soul\",\"07_-_Revolver\",\"07_-_Revolver\",\"08_-_Sgt._Pepper's_Lonely_Hearts_Club_Band\",\"09_-_Magical_Mystery_Tour\",\"09_-_Magical_Mystery_Tour\",\"10CD2_-_The_Beatles\"]\n",
    "\n",
    "# LPF order and frequency for filtering (Butterworth) of HPSS signal before going into CREPE \n",
    "filer_order = 4\n",
    "filter_frequency = 250\n",
    "\n",
    "# Used to avoid plotting\n",
    "should_plot = False\n",
    "# Used to avoid full computation of CREPE\n",
    "full_computation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 10s 25ms/step\n",
      "415/415 [==============================] - 10s 24ms/step\n",
      "405/405 [==============================] - 10s 24ms/step\n",
      "522/522 [==============================] - 12s 24ms/step\n",
      "456/456 [==============================] - 10s 22ms/step\n",
      "383/383 [==============================] - 8s 22ms/step\n",
      "523/523 [==============================] - 11s 22ms/step\n",
      "564/564 [==============================] - 13s 22ms/step\n",
      "575/575 [==============================] - 13s 22ms/step\n",
      "520/520 [==============================] - 12s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "for song_num in range(len(song_names)):\n",
    "    song_name = song_names[song_num]\n",
    "    album_name = album_names[song_num]\n",
    "    \n",
    "    root_dir = \"The Beatles Annotations/\"\n",
    "    chord_path = root_dir + \"chords/The Beatles/\" + album_name + \"/\" + song_name + \".lab\"\n",
    "    beat_path = root_dir + \"beat/The Beatles/\" + album_name + \"/\" + song_name + \".txt\"\n",
    "    key_path = root_dir + \"keylab/The Beatles/\" + album_name + \"/\" + song_name + \".lab\"\n",
    "    audio_file = root_dir + \"Audio/\" + song_name + \".wav\"\n",
    "    audio, fs = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    ref_song_key = get_key_truth(key_path)\n",
    "    \n",
    "    # Key estimation from madmom. Needed for bass note reference -> Ground Truth\n",
    "    key_prob = CNNKeyRecognitionProcessor()(audio_file) \n",
    "    key = key_prediction_to_label(key_prob)\n",
    "    \n",
    "    # Collecting chord labels and time intervals from dataset\n",
    "    ref_chord_intervals, ref_chord_labels = get_chord_truth(chord_path)\n",
    "    ref_bass_note = get_bass_notes(ref_chord_labels, key)\n",
    "    ref_bass_midi = bass_notes_to_midi(ref_bass_note)\n",
    "    \n",
    "    # Get Chroma:\n",
    "    dcp = DeepChromaProcessor() \n",
    "    chroma = dcp(audio_file)\n",
    "\n",
    "    # Get Chords:\n",
    "    decode = DeepChromaChordRecognitionProcessor()\n",
    "    chords = decode(chroma)\n",
    "    est_chord_intervals = np.array([(x[0], x[1]) for x in chords])\n",
    "    est_chord_labels = np.array([x[2] for x in chords])\n",
    "    \n",
    "    # Get the Beat estimations throught an estimated activation function\n",
    "    est_activation_function = RNNBeatProcessor()(audio_file)\n",
    "    est_beats = BeatTrackingProcessor(fps=100)(est_activation_function)\n",
    "    \n",
    "    # Expand est_beats to make est_beat_intervals\n",
    "    est_beat_intervals = np.concatenate((est_beats[0:-1, None], est_beats[1:, None]), 1)\n",
    "\n",
    "    #Find the first chord interval greater than each est_beat\n",
    "    idx = np.greater.outer(est_beats, est_chord_intervals[:,0])\n",
    "    idx = np.argmin(idx, axis=1) - 1\n",
    "    est_chord_labels_expanded = est_chord_labels[idx[:-1]]\n",
    "    \n",
    "    #Find the first chord interval greater than each est_beat\n",
    "    idx = np.greater.outer(est_beats, ref_chord_intervals[:,0])\n",
    "    idx = np.argmin(idx, axis=1) - 1\n",
    "    ref_bass_midi_expanded = ref_bass_midi[idx[:-1]]\n",
    "    ref_chord_labels_expanded = ref_chord_labels[idx[:-1]]\n",
    "    \n",
    "    # Back to Time Domain\n",
    "    h = audio\n",
    "        \n",
    "    # Filter the IFFT of HPSS decomposition (only harmonic) signal to get only the lower octaves\n",
    "    [b, a] = sg.butter(filer_order, filter_frequency, fs=fs) # Double check higher limit?\n",
    "    hFilt = sg.lfilter(b, a, h)\n",
    "    \n",
    "    # Run Crepe algo in low passed HPSS decomposition to get bass note\n",
    "    if full_computation:\n",
    "        [time_axis, bass_f0, confidence, _] = crepe.predict(hFilt, sr=fs, viterbi=True, model_capacity='full')\n",
    "    else:\n",
    "        [time_axis, bass_f0, confidence, _] = crepe.predict(hFilt, sr=fs, viterbi=True, model_capacity='tiny')\n",
    "        \n",
    "    # Get bass note for each chord as strings\n",
    "    est_bass_note_expanded = estimate_bass_note(bass_f0, time_axis, est_beat_intervals, est_chord_labels_expanded)\n",
    "    est_bass_note = estimate_bass_note(bass_f0, time_axis, est_chord_intervals, est_chord_labels)\n",
    "    \n",
    "    est_bass_midi = librosa.note_to_midi(est_bass_note)\n",
    "    est_bass_midi = np.mod(est_bass_midi, 12)\n",
    "    est_bass_midi_expanded = librosa.note_to_midi(est_bass_note_expanded)\n",
    "    est_bass_midi_expanded = np.mod(est_bass_midi_expanded, 12)\n",
    "\n",
    "    est_bass_midi0 = librosa.hz_to_midi(bass_f0)\n",
    "    est_bass_midi0 = np.round(est_bass_midi0)\n",
    "    est_bass_midi0 = np.mod(est_bass_midi0, 12)\n",
    "    \n",
    "    if should_plot:\n",
    "        plt.figure(figsize=(18, 8))\n",
    "        plt.subplot(211)\n",
    "        # plt.plot(est_chord_intervals.reshape(-1), est_bass_midi.repeat(2))\n",
    "        plt.plot(est_beat_intervals.reshape(-1), est_bass_midi_expanded.repeat(2))\n",
    "        # plt.plot(time_axis, est_bass_midi0)\n",
    "        plt.plot(est_beat_intervals.reshape(-1) * 0.992, ref_bass_midi_expanded.repeat(2), \":\")\n",
    "        plt.xlim(ref_intervals.reshape(-1)[[1, -1]])\n",
    "        plt.ylim([0, 12])\n",
    "        ticks = np.arange(12);\n",
    "        plt.yticks(ticks, librosa.midi_to_note(ticks, octave=False))\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Note\")\n",
    "        plt.title(\"Bass Note Compaison\")\n",
    "        plt.grid(True)\n",
    "        plt.legend([\"Estimated\", \"Reference\"])\n",
    "        # plt.xlim([25, 100])\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.stem(est_chord_intervals[:,0], np.ones_like(est_chord_intervals[:,0]))\n",
    "        plt.xlim(ref_intervals.reshape(-1)[[1, -1]])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.grid(True)\n",
    "        # plt.xlim([25, 100])\n",
    "        \n",
    "    est_chord_labels_expanded_combined = combine_chord_and_bass_labels(est_chord_labels_expanded, est_bass_note_expanded)\n",
    "\n",
    "    score1 = mir_eval.chord.thirds_inv(ref_chord_labels_expanded, est_chord_labels_expanded_combined)\n",
    "    score2 = mir_eval.chord.thirds(ref_chord_labels_expanded, est_chord_labels_expanded_combined)\n",
    "    idx = np.where(score2 == 1)\n",
    "    score3 = score1[idx]\n",
    "\n",
    "    mean_score1 = np.append(mean_score1,np.mean(score1))\n",
    "    mean_score2 = np.append(mean_score2,np.mean(score2))\n",
    "    mean_score3 = np.append(mean_score3,np.mean(score3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48704663, 0.41240876, 0.64516129, 0.4213198 , 0.71818182,\n",
       "       0.57931034, 0.57731959, 0.39849624, 0.54085603, 0.54705882])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'07_-_Please_Please_Me': '01_-_Please_Please_Me',\n",
       " '03_-_All_My_Loving': '02_-_With_the_Beatles',\n",
       " '13_-_Yesterday': '05_-_Help!',\n",
       " '07_-_Michelle': '06_-_Rubber_Soul',\n",
       " '05_-_Here,_There_And_Everywhere': '07_-_Revolver',\n",
       " '10_-_For_No_One': '07_-_Revolver',\n",
       " '04_-_Getting_Better': \"08_-_Sgt._Pepper's_Lonely_Hearts_Club_Band\",\n",
       " '02_-_The_Fool_On_The_Hill': '09_-_Magical_Mystery_Tour',\n",
       " '09_-_Penny_Lane': '09_-_Magical_Mystery_Tour',\n",
       " \"CD2_-_03_-_Mother_Nature's_Son\": '10CD2_-_The_Beatles'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(song_names,album_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
